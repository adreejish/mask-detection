{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": "import tensorflow as tf\nfrom matplotlib import pyplot as plt\nfrom tensorflow.keras.preprocessing.image import img_to_array, load_img\nimport numpy as np\nimport cv2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\nfrom tensorflow.keras import backend as K"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": "#create the model and load in the pretrained weigths \n\ndef buildmodel():\n    img_width, img_height = 150, 150\n\n    train_data_dir = 'dataset/train'\n    validation_data_dir = 'dataset/validation'\n\n    epochs = 50\n    batch_size = 16\n\n    if K.image_data_format() == 'channels_first':\n        input_shape = (3, img_width, img_height)\n    else:\n        input_shape = (img_width, img_height, 3)\n\n    model = Sequential()\n    model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(32, (3, 3)))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(64, (3, 3)))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Flatten())\n    model.add(Dense(64))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(1))\n    model.add(Activation('sigmoid'))\n    model.load_weights('second_try.h5')\n    model2 = cv2.dnn.readNetFromCaffe('deploy.prototxt.txt', \n                                 'res10_300x300_ssd_iter_140000.caffemodel')\n    return model,model2"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": "#process the image before feeding it into the model for prediction\n\ndef process(image_path):\n    img_width, img_height = 150, 150\n\n    img = load_img(image_path,False,target_size=(img_width,img_height))\n    x = img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n    return x"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": "#detect the face, extract it from the image and pass it through the face mask classifier. Return the image with bounding boxes\n\ndef detect(path,conf,model,model2):\n    CONF_THR = conf\n    img=(cv2.imread(path))\n    #print(img)\n    outimg=img.copy()\n    h, w = img.shape[0:2]\n    blob = cv2.dnn.blobFromImage(img, 1, (300*w//h,300), (104,177,123), False)\n    model2.setInput(blob)\n    output = model2.forward()\n    \n    for i in range(output.shape[2]):\n        conf = output[0,0,i,2]\n        if conf > CONF_THR:\n            label = output[0,0,i,1]\n            x0,y0,x1,y1 = (output[0,0,i,3:7] * [w,h,w,h]).astype(int)\n            box = output[0, 0, i, 3:7] * np.array([w, h, w, h])\n            (startX, startY, endX, endY) = box.astype(\"int\")\n            (startX, startY) = (max(0, startX), max(0, startY))\n            (endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n            face = img[startY:endY, startX:endX]\n            if not face.any():\n                pass\n            else:\n                cv2.imwrite('detface.jpg',face)\n                read_face=process('detface.jpg')\n                preds=model.predict(read_face)\n                if preds[0][0]==0:\n                    text = \"mask\"\n                    y = startY - 10 if startY - 10 > 10 else startY + 10\n                    #print ('masked')\n                    cv2.rectangle(outimg, (x0,y0), (x1,y1), (0,0,255), 5)\n                    cv2.putText(outimg, text, (startX, y),\n                    cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n                else:\n                    text = \"no mask\"\n                    y = startY - 10 if startY - 10 > 10 else startY + 10\n                    #print('no mask')\n                    cv2.rectangle(outimg, (x0,y0), (x1,y1), (255,0,0), 5)\n                    cv2.putText(outimg, text, (startX, y),\n                    cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255,0,0), 2)\n\n    \n    return outimg\n    "
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": "#loop through each frame and pass it for prediction. \ndef pred_mask(vidpath,conf,model,model2):\n    vidpath=vidpath\n    conf=conf\n    model=model\n    model2=model2\n    \n    cap = cv2.VideoCapture(vidpath)\n    while True:\n        ret, frame = cap.read()\n        cv2.imwrite('currentframe.jpeg',frame)\n        img=detect('currentframe.jpeg',conf,model,model2)\n        imS = cv2.resize(img, (960, 540))\n        cv2.imshow('frame',imS)\n        if cv2.waitKey(1) & 0xFF == ord('q'):\n            break\n    cap.release()\n    cv2.destroyAllWindows()"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": "#q to exit\nmodel,model2=buildmodel()\npred_mask(\"masklady.mp4\",0.15,model,model2)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "penv",
   "language": "python",
   "name": "penv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
